
R version 4.0.0 (2020-04-24) -- "Arbor Day"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin17.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "personalized"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('personalized')
Loading required package: glmnet
Loading required package: Matrix
Loaded glmnet 4.0-2
Loading required package: mgcv
Loading required package: nlme
This is mgcv 1.8-31. For overview type 'help("mgcv-package")'.
Loading required package: gbm
Loaded gbm 2.1.6
Loading required package: ggplot2
Loading required package: plotly

Attaching package: ‘plotly’

The following object is masked from ‘package:ggplot2’:

    last_plot

The following object is masked from ‘package:stats’:

    filter

The following object is masked from ‘package:graphics’:

    layout

> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("LaLonde")
> ### * LaLonde
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: LaLonde
> ### Title: National Supported Work Study Data
> ### Aliases: LaLonde
> ### Keywords: datasets
> 
> ### ** Examples
> 
> data(LaLonde)
> y <- LaLonde$outcome
> 
> trt <- LaLonde$treat
> 
> x.varnames <- c("age", "educ", "black", "hisp", "white",
+                 "marr", "nodegr", "log.re75", "u75")
> 
> # covariates
> data.x <- LaLonde[, x.varnames]
> 
> # construct design matrix (with no intercept)
> x <- model.matrix(~ -1 + ., data = data.x)
> 
> const.propens <- function(x, trt)
+ {
+     mean.trt <- mean(trt == "Trt")
+     rep(mean.trt, length(trt))
+ }
> 
> subgrp_fit_w <- fit.subgroup(x = x, y = y, trt = trt,
+     loss = "logistic_loss_lasso",
+     propensity.func = const.propens,
+     cutpoint = 0,
+     type.measure = "auc",
+     nfolds = 10)
> 
> summary(subgrp_fit_w)
family:    binomial 
loss:      logistic_loss_lasso 
method:    weighting 
cutpoint:  0 
propensity 
function:  propensity.func 

benefit score: f(x), 
Trt recom = Trt*I(f(x)>c)+Ctrl*I(f(x)<=c) where c is 'cutpoint'

Average Outcomes:
              Recommended Ctrl  Recommended Trt
Received Ctrl  0.7292 (n = 48) 0.5146 (n = 377)
Received Trt   0.5714 (n = 28) 0.6059 (n = 269)

Treatment effects conditional on subgroups:
Est of E[Y|T=Ctrl,Recom=Ctrl]-E[Y|T=/=Ctrl,Recom=Ctrl] 
                                       0.1577 (n = 76) 
    Est of E[Y|T=Trt,Recom=Trt]-E[Y|T=/=Trt,Recom=Trt] 
                                      0.0914 (n = 646) 

NOTE: The above average outcomes are biased estimates of
      the expected outcomes conditional on subgroups. 
      Use 'validate.subgroup()' to obtain unbiased estimates.

---------------------------------------------------

Benefit score quantiles (f(X) for Trt vs Ctrl): 
     0%     25%     50%     75%    100% 
-0.2423  0.1320  0.1320  0.1320  0.3470 

---------------------------------------------------

Summary of individual treatment effects: 
E[Y|T=Trt, X] - E[Y|T=Ctrl, X]

    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.12056  0.06592  0.06592  0.06346  0.06592  0.17177 

---------------------------------------------------

2 out of 10 interactions selected in total by the lasso (cross validation criterion).

The first estimate is the treatment main effect, which is always selected. 
Any other variables selected represent treatment-covariate interactions.

           Trt hispYes marrYes
Estimate 0.132 -0.3743  0.2149
> 
> 
> 
> cleanEx()
> nameEx("check.overlap")
> ### * check.overlap
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: check.overlap
> ### Title: Check propensity score overlap
> ### Aliases: check.overlap
> 
> ### ** Examples
> 
> library(personalized)
> 
> set.seed(123)
> n.obs  <- 250
> n.vars <- 15
> x <- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)
> 
> 
> # simulate non-randomized treatment
> xbetat   <- 0.25 + 0.5 * x[,11] - 0.5 * x[,12]
> trt.prob <- exp(xbetat) / (1 + exp(xbetat))
> trt01    <- rbinom(n.obs, 1, prob = trt.prob)
> 
> # create function for fitting propensity score model
> prop.func <- function(x, trt)
+ {
+     # fit propensity score model
+     propens.model <- cv.glmnet(y = trt,
+                                x = x, family = "binomial")
+     pi.x <- predict(propens.model, s = "lambda.min",
+                     newx = x, type = "response")[,1]
+     pi.x
+ }
> 
> check.overlap(x = x,
+               trt = trt01,
+               propensity.func = prop.func)
> 
> # now add density plot with histogram
> check.overlap(x = x,
+               trt = trt01,
+               type = "both",
+               propensity.func = prop.func)
> 
> 
> # simulated non-randomized treatment with multiple levels
> xbetat_1   <- 0.15 + 0.5 * x[,9] - 0.25 * x[,12]
> xbetat_2   <- 0.15 - 0.5 * x[,11] + 0.25 * x[,15]
> trt.1.prob <- exp(xbetat_1) / (1 + exp(xbetat_1) + exp(xbetat_2))
> trt.2.prob <- exp(xbetat_2) / (1 + exp(xbetat_1) + exp(xbetat_2))
> trt.3.prob <- 1 - (trt.1.prob + trt.2.prob)
> prob.mat <- cbind(trt.1.prob, trt.2.prob, trt.3.prob)
> trt    <- apply(prob.mat, 1, function(rr) rmultinom(1, 1, prob = rr))
> trt    <- apply(trt, 2, function(rr) which(rr == 1))
> 
> # use multinomial logistic regression model with lasso penalty for propensity
> propensity.multinom.lasso <- function(x, trt)
+ {
+     if (!is.factor(trt)) trt <- as.factor(trt)
+     gfit <- cv.glmnet(y = trt, x = x, family = "multinomial")
+ 
+     # predict returns a matrix of probabilities:
+     # one column for each treatment level
+     propens <- drop(predict(gfit, newx = x, type = "response", s = "lambda.min",
+                             nfolds = 5, alpha = 0))
+ 
+     # return the probability corresponding to the
+     # treatment that was observed
+     probs <- propens[,match(levels(trt), colnames(propens))]
+ 
+     probs
+ }
> 
> check.overlap(x = x,
+               trt = trt,
+               type = "histogram",
+               propensity.func = propensity.multinom.lasso)
> 
> 
> 
> 
> 
> 
> cleanEx()
> nameEx("create.augmentation.function")
> ### * create.augmentation.function
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: create.augmentation.function
> ### Title: Creation of augmentation functions
> ### Aliases: create.augmentation.function
> 
> ### ** Examples
> 
> library(personalized)
> 
> set.seed(123)
> n.obs  <- 500
> n.vars <- 15
> x <- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)
> 
> 
> # simulate non-randomized treatment
> xbetat   <- 0.5 + 0.5 * x[,7] - 0.5 * x[,9]
> trt.prob <- exp(xbetat) / (1 + exp(xbetat))
> trt01    <- rbinom(n.obs, 1, prob = trt.prob)
> 
> trt      <- 2 * trt01 - 1
> 
> # simulate response
> # delta below drives treatment effect heterogeneity
> delta <- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12] )
> xbeta <- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13] + 0.5 * x[,15] ^ 2
> xbeta <- xbeta + delta * trt
> 
> # continuous outcomes
> y <- drop(xbeta) + rnorm(n.obs, sd = 2)
> 
> aug.func <- create.augmentation.function(family = "gaussian",
+                                          crossfit = TRUE,
+                                          nfolds.crossfit = 10,
+                                          cv.glmnet.args = list(type.measure = "mae",
+                                                                nfolds = 5))
> 
> prop.func <- create.propensity.function(crossfit = TRUE,
+                                         nfolds.crossfit = 10,
+                                         cv.glmnet.args = list(type.measure = "auc",
+                                                               nfolds = 5))
> 
> subgrp.model <- fit.subgroup(x = x, y = y,
+                              trt = trt01,
+                              propensity.func = prop.func,
+                              augment.func = aug.func,
+                              loss   = "sq_loss_lasso",
+                              nfolds = 10)    # option for cv.glmnet (for ITR estimation)
> 
> summary(subgrp.model)
family:    gaussian 
loss:      sq_loss_lasso 
method:    weighting 
cutpoint:  0 
augmentation 
function: augment.func 
propensity 
function:  propensity.func 

benefit score: f(x), 
Trt recom = 1*I(f(x)>c)+0*I(f(x)<=c) where c is 'cutpoint'

Average Outcomes:
                Recommended 0      Recommended 1
Received 0    -7.715 (n = 65) -19.2198 (n = 136)
Received 1 -24.5087 (n = 104)  -4.1609 (n = 195)

Treatment effects conditional on subgroups:
Est of E[Y|T=0,Recom=0]-E[Y|T=/=0,Recom=0] 
                         16.7937 (n = 169) 
Est of E[Y|T=1,Recom=1]-E[Y|T=/=1,Recom=1] 
                         15.0589 (n = 331) 

NOTE: The above average outcomes are biased estimates of
      the expected outcomes conditional on subgroups. 
      Use 'validate.subgroup()' to obtain unbiased estimates.

---------------------------------------------------

Benefit score quantiles (f(X) for 1 vs 0): 
     0%     25%     50%     75%    100% 
-16.840  -1.804   2.800   7.160  19.574 

---------------------------------------------------

Summary of individual treatment effects: 
E[Y|T=1, X] - E[Y|T=0, X]

   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-33.679  -3.608   5.601   5.640  14.320  39.149 

---------------------------------------------------

5 out of 15 interactions selected in total by the lasso (cross validation criterion).

The first estimate is the treatment main effect, which is always selected. 
Any other variables selected represent treatment-covariate interactions.

           Trt1     V2      V3     V11    V13    V15
Estimate 2.9976 1.0859 -1.7697 -0.7164 0.4004 0.2949
> 
> 
> 
> 
> cleanEx()
> nameEx("create.propensity.function")
> ### * create.propensity.function
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: create.propensity.function
> ### Title: Creation of propensity fitting function
> ### Aliases: create.propensity.function
> 
> ### ** Examples
> 
> library(personalized)
> 
> set.seed(123)
> n.obs  <- 500
> n.vars <- 15
> x <- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)
> 
> 
> # simulate non-randomized treatment
> xbetat   <- 0.5 + 0.5 * x[,7] - 0.5 * x[,9]
> trt.prob <- exp(xbetat) / (1 + exp(xbetat))
> trt01    <- rbinom(n.obs, 1, prob = trt.prob)
> 
> trt      <- 2 * trt01 - 1
> 
> # simulate response
> # delta below drives treatment effect heterogeneity
> delta <- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12] )
> xbeta <- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13] + 0.5 * x[,15] ^ 2
> xbeta <- xbeta + delta * trt
> 
> # continuous outcomes
> y <- drop(xbeta) + rnorm(n.obs, sd = 2)
> 
> aug.func <- create.augmentation.function(family = "gaussian",
+                                          crossfit = TRUE,
+                                          nfolds.crossfit = 10,
+                                          cv.glmnet.args = list(type.measure = "mae",
+                                                                nfolds = 5))
> 
> prop.func <- create.propensity.function(crossfit = TRUE,
+                                         nfolds.crossfit = 10,
+                                         cv.glmnet.args = list(type.measure = "mae",
+                                                               nfolds = 5))
> 
> subgrp.model <- fit.subgroup(x = x, y = y,
+                              trt = trt01,
+                              propensity.func = prop.func,
+                              augment.func = aug.func,
+                              loss   = "sq_loss_lasso",
+                              nfolds = 10)    # option for cv.glmnet (for ITR estimation)
> 
> summary(subgrp.model)
family:    gaussian 
loss:      sq_loss_lasso 
method:    weighting 
cutpoint:  0 
augmentation 
function: augment.func 
propensity 
function:  propensity.func 

benefit score: f(x), 
Trt recom = 1*I(f(x)>c)+0*I(f(x)<=c) where c is 'cutpoint'

Average Outcomes:
                Recommended 0      Recommended 1
Received 0   -7.2029 (n = 84) -28.7306 (n = 117)
Received 1 -26.6205 (n = 114)  -2.9403 (n = 185)

Treatment effects conditional on subgroups:
Est of E[Y|T=0,Recom=0]-E[Y|T=/=0,Recom=0] 
                         19.4176 (n = 198) 
Est of E[Y|T=1,Recom=1]-E[Y|T=/=1,Recom=1] 
                         25.7903 (n = 302) 

NOTE: The above average outcomes are biased estimates of
      the expected outcomes conditional on subgroups. 
      Use 'validate.subgroup()' to obtain unbiased estimates.

---------------------------------------------------

Benefit score quantiles (f(X) for 1 vs 0): 
     0%     25%     50%     75%    100% 
-35.936  -5.774   2.999  12.148  43.013 

---------------------------------------------------

Summary of individual treatment effects: 
E[Y|T=1, X] - E[Y|T=0, X]

   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-71.871 -11.547   5.997   7.096  24.295  86.025 

---------------------------------------------------

9 out of 15 interactions selected in total by the lasso (cross validation criterion).

The first estimate is the treatment main effect, which is always selected. 
Any other variables selected represent treatment-covariate interactions.

           Trt1     V2      V3     V6     V8      V9    V10     V11    V13
Estimate 3.7311 2.3497 -2.6714 0.7016 1.2338 -0.3431 0.9364 -1.0806 1.5617
            V15
Estimate 1.1872
> 
> 
> 
> 
> cleanEx()
> nameEx("fit.subgroup")
> ### * fit.subgroup
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: fit.subgroup
> ### Title: Fitting subgroup identification models
> ### Aliases: fit.subgroup
> 
> ### ** Examples
> 
> library(personalized)
> 
> set.seed(123)
> n.obs  <- 500
> n.vars <- 15
> x <- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)
> 
> 
> # simulate non-randomized treatment
> xbetat   <- 0.5 + 0.5 * x[,7] - 0.5 * x[,9]
> trt.prob <- exp(xbetat) / (1 + exp(xbetat))
> trt01    <- rbinom(n.obs, 1, prob = trt.prob)
> 
> trt      <- 2 * trt01 - 1
> 
> # simulate response
> # delta below drives treatment effect heterogeneity
> delta <- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12] )
> xbeta <- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13] + 0.5 * x[,15] ^ 2
> xbeta <- xbeta + delta * trt
> 
> # continuous outcomes
> y <- drop(xbeta) + rnorm(n.obs, sd = 2)
> 
> # binary outcomes
> y.binary <- 1 * (xbeta + rnorm(n.obs, sd = 2) > 0 )
> 
> # count outcomes
> y.count <- round(abs(xbeta + rnorm(n.obs, sd = 2)))
> 
> # time-to-event outcomes
> surv.time <- exp(-20 - xbeta + rnorm(n.obs, sd = 1))
> cens.time <- exp(rnorm(n.obs, sd = 3))
> y.time.to.event  <- pmin(surv.time, cens.time)
> status           <- 1 * (surv.time <= cens.time)
> 
> # create function for fitting propensity score model
> prop.func <- function(x, trt)
+ {
+     # fit propensity score model
+     propens.model <- cv.glmnet(y = trt,
+                                x = x, family = "binomial")
+     pi.x <- predict(propens.model, s = "lambda.min",
+                     newx = x, type = "response")[,1]
+     pi.x
+ }
> 
> 
> ####################  Continuous outcomes ################################
> 
> 
> subgrp.model <- fit.subgroup(x = x, y = y,
+                            trt = trt01,
+                            propensity.func = prop.func,
+                            loss   = "sq_loss_lasso",
+                            nfolds = 10)              # option for cv.glmnet
> 
> summary(subgrp.model)
family:    gaussian 
loss:      sq_loss_lasso 
method:    weighting 
cutpoint:  0 
propensity 
function:  propensity.func 

benefit score: f(x), 
Trt recom = 1*I(f(x)>c)+0*I(f(x)<=c) where c is 'cutpoint'

Average Outcomes:
                Recommended 0      Recommended 1
Received 0   -5.4606 (n = 81) -27.2778 (n = 120)
Received 1 -26.8929 (n = 124)  -1.6271 (n = 175)

Treatment effects conditional on subgroups:
Est of E[Y|T=0,Recom=0]-E[Y|T=/=0,Recom=0] 
                         21.4323 (n = 205) 
Est of E[Y|T=1,Recom=1]-E[Y|T=/=1,Recom=1] 
                         25.6507 (n = 295) 

NOTE: The above average outcomes are biased estimates of
      the expected outcomes conditional on subgroups. 
      Use 'validate.subgroup()' to obtain unbiased estimates.

---------------------------------------------------

Benefit score quantiles (f(X) for 1 vs 0): 
     0%     25%     50%     75%    100% 
-32.002  -4.996   2.423   9.251  29.137 

---------------------------------------------------

Summary of individual treatment effects: 
E[Y|T=1, X] - E[Y|T=0, X]

   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-64.004  -9.993   4.846   4.793  18.502  58.274 

---------------------------------------------------

10 out of 15 interactions selected in total by the lasso (cross validation criterion).

The first estimate is the treatment main effect, which is always selected. 
Any other variables selected represent treatment-covariate interactions.

           Trt1     V2      V3      V5   V6      V7     V8    V10     V11
Estimate 2.6463 2.2645 -2.1415 -0.1068 0.43 -0.0028 0.5195 0.5581 -0.8164
            V13    V15
Estimate 1.3847 0.5343
> 
> # estimates of the individual-specific
> # treatment effect estimates:
> subgrp.model$individual.trt.effects
Summary of individual treatment effects: 
E[Y|T=1, X] - E[Y|T=0, X]

   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-64.004  -9.993   4.846   4.793  18.502  58.274 
> 
> # fit lasso + gam model with REML option for gam
> 
> 
> ####################  Using an augmentation function #####################
> ## augmentation funcions involve modeling the conditional mean E[Y|T, X]
> ## and returning predictions that are averaged over the treatment values
> ## return <- 1/2 * (hat{E}[Y|T=1, X] + hat{E}[Y|T=-1, X])
> ##########################################################################
> 
> augment.func <- function(x, y, trt) {
+     data <- data.frame(x, y, trt)
+     xm <- model.matrix(y~trt*x-1, data = data)
+ 
+     lmod <- cv.glmnet(y = y, x = xm)
+     ## get predictions when trt = 1
+     data$trt <- 1
+     xm <- model.matrix(y~trt*x-1, data = data)
+     preds_1  <- predict(lmod, xm, s = "lambda.min")
+ 
+     ## get predictions when trt = -1
+     data$trt <- -1
+     xm <- model.matrix(y~trt*x-1, data = data)
+     preds_n1  <- predict(lmod, xm, s = "lambda.min")
+ 
+     ## return predictions averaged over trt
+     return(0.5 * (preds_1 + preds_n1))
+ }
> 
> 
> ####################  Binary outcomes ####################################
> 
> # use logistic loss for binary outcomes
> subgrp.model.bin <- fit.subgroup(x = x, y = y.binary,
+                            trt = trt01,
+                            propensity.func = prop.func,
+                            loss   = "logistic_loss_lasso",
+                            type.measure = "auc",    # option for cv.glmnet
+                            nfolds = 5)              # option for cv.glmnet
> 
> subgrp.model.bin
family:    binomial 
loss:      logistic_loss_lasso 
method:    weighting 
cutpoint:  0 
propensity 
function:  propensity.func 

benefit score: f(x), 
Trt recom = 1*I(f(x)>c)+0*I(f(x)<=c) where c is 'cutpoint'

Average Outcomes:
             Recommended 0    Recommended 1
Received 0 0.5081 (n = 86)  0.175 (n = 115)
Received 1 0.161 (n = 139) 0.5935 (n = 160)

Treatment effects conditional on subgroups:
Est of E[Y|T=0,Recom=0]-E[Y|T=/=0,Recom=0] 
                          0.3471 (n = 225) 
Est of E[Y|T=1,Recom=1]-E[Y|T=/=1,Recom=1] 
                          0.4185 (n = 275) 

NOTE: The above average outcomes are biased estimates of
      the expected outcomes conditional on subgroups. 
      Use 'validate.subgroup()' to obtain unbiased estimates.

---------------------------------------------------

Benefit score quantiles (f(X) for 1 vs 0): 
     0%     25%     50%     75%    100% 
-2.5067 -0.4946  0.1390  0.7694  2.7836 

---------------------------------------------------

Summary of individual treatment effects: 
E[Y|T=1, X] - E[Y|T=0, X]

    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-0.84922 -0.24237  0.06937  0.06463  0.36680  0.88357 
> 
> 
> ####################  Count outcomes #####################################
> 
> # use poisson loss for count/poisson outcomes
> subgrp.model.poisson <- fit.subgroup(x = x, y = y.count,
+                            trt = trt01,
+                            propensity.func = prop.func,
+                            loss   = "poisson_loss_lasso",
+                            type.measure = "mse",    # option for cv.glmnet
+                            nfolds = 5)              # option for cv.glmnet
> 
> subgrp.model.poisson
family:    poisson 
loss:      poisson_loss_lasso 
method:    weighting 
cutpoint:  0 
propensity 
function:  propensity.func 

benefit score: f(x), 
Trt recom = 1*I(f(x)>c)+0*I(f(x)<=c) where c is 'cutpoint'

Average Outcomes:
               Recommended 0     Recommended 1
Received 0  31.298 (n = 117)  16.1943 (n = 84)
Received 1 17.9003 (n = 158) 26.9485 (n = 141)

Treatment effects conditional on subgroups:
Est of E[Y|T=0,Recom=0]-E[Y|T=/=0,Recom=0] 
                         13.3977 (n = 275) 
Est of E[Y|T=1,Recom=1]-E[Y|T=/=1,Recom=1] 
                         10.7543 (n = 225) 

NOTE: The above average outcomes are biased estimates of
      the expected outcomes conditional on subgroups. 
      Use 'validate.subgroup()' to obtain unbiased estimates.

---------------------------------------------------

Benefit score quantiles (f(X) for 1 vs 0): 
     0%     25%     50%     75%    100% 
-3.4047 -1.0683 -0.1849  0.6676  3.5395 

---------------------------------------------------

Summary of individual treatment effects: 
E[Y|T=1, X] - E[Y|T=0, X]

    Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
-30.0708  -2.5668  -0.3720  -0.8084   1.4365  34.4199 
> 
> 
> ####################  Time-to-event outcomes #############################
> 
> library(survival)
> 
> 
> ####################  Using custom loss functions ########################
> 
> ## Use custom loss function for binary outcomes
> 
> fit.custom.loss.bin <- function(x, y, weights, offset, ...) {
+     df <- data.frame(y = y, x)
+ 
+     # minimize logistic loss with NO lasso penalty
+     # with allowance for efficiency augmentation
+     glmf <- glm(y ~ x - 1, weights = weights,
+                 offset = offset, # offset term allows for efficiency augmentation
+                 family = binomial(), ...)
+ 
+     # save coefficients
+     cfs = coef(glmf)
+ 
+     # create prediction function.
+     prd = function(x, type = "response") {
+          dfte <- cbind(1, x)
+          colnames(dfte) <- names(cfs)
+          ## predictions must be returned on the scale
+          ## of the linear predictor
+          predict(glmf, data.frame(dfte), type = "link")
+     }
+     # return lost of required components
+     list(predict = prd, model = glmf, coefficients = cfs)
+ }
> 
> 
> 
> ## try exponential loss for
> ## positive outcomes
> 
> fit.expo.loss <- function(x, y, weights, ...)
+ {
+     expo.loss <- function(beta, x, y, weights) {
+         sum(weights * y * exp(-drop(x %*% beta)))
+     }
+ 
+     # use optim() to minimize loss function
+     opt <- optim(rep(0, NCOL(x)), fn = expo.loss, x = x, y = y, weights = weights)
+ 
+     coefs <- opt$par
+ 
+     pred <- function(x, type = "response") {
+         tcrossprod(cbind(1, x), t(coefs))
+     }
+ 
+     # return list of required components
+     list(predict = pred, model = opt, coefficients = coefs)
+ }
> 
> 
> 
> 
> 
> 
> cleanEx()

detaching ‘package:survival’

> nameEx("plot")
> ### * plot
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plot.subgroup_fitted
> ### Title: Plotting results for fitted subgroup identification models
> ### Aliases: plot.subgroup_fitted plot.subgroup_validated
> 
> ### ** Examples
> 
> library(personalized)
> 
> set.seed(123)
> n.obs  <- 250
> n.vars <- 15
> x <- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)
> 
> 
> # simulate non-randomized treatment
> xbetat   <- 0.5 + 0.5 * x[,11] - 0.5 * x[,13]
> trt.prob <- exp(xbetat) / (1 + exp(xbetat))
> trt01    <- rbinom(n.obs, 1, prob = trt.prob)
> 
> trt      <- 2 * trt01 - 1
> 
> # simulate response
> delta <- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12])
> xbeta <- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13]
> xbeta <- xbeta + delta * trt
> 
> # continuous outcomes
> y <- drop(xbeta) + rnorm(n.obs, sd = 2)
> 
> # create function for fitting propensity score model
> prop.func <- function(x, trt)
+ {
+     # fit propensity score model
+     propens.model <- cv.glmnet(y = trt,
+                                x = x, family = "binomial")
+     pi.x <- predict(propens.model, s = "lambda.min",
+                     newx = x, type = "response")[,1]
+     pi.x
+ }
> 
> subgrp.model <- fit.subgroup(x = x, y = y,
+                            trt = trt01,
+                            propensity.func = prop.func,
+                            loss   = "sq_loss_lasso",
+                            nfolds = 5)              # option for cv.glmnet
> 
> subgrp.model$subgroup.trt.effects
$subgroup.effects
Est of E[Y|T=0,Recom=0]-E[Y|T=/=0,Recom=0] 
                                  8.769986 
Est of E[Y|T=1,Recom=1]-E[Y|T=/=1,Recom=1] 
                                 16.819638 

$avg.outcomes
           Recommended 0 Recommended 1
Received 0     -11.59931     -27.78629
Received 1     -20.36929     -10.96665

$sample.sizes
           Recommended 0 Recommended 1
Received 0            18            81
Received 1            86            65

$overall.subgroup.effect
[1] 13.46568

> 
> plot(subgrp.model)
> 
> plot(subgrp.model, type = "boxplot")
> 
> plot(subgrp.model, type = "interaction")
> 
> plot(subgrp.model, type = "conditional")
`geom_smooth()` using formula 'y ~ s(x, bs = "cs")'
> 
> valmod <- validate.subgroup(subgrp.model, B = 3,
+                           method = "training_test",
+                           benefit.score.quantiles = c(0.25, 0.5, 0.75),
+                           train.fraction = 0.75)
> 
> plot(valmod)
> 
> 
> plot(valmod, type = "interaction")
> 
> # see how summary statistics of subgroups change
> # when the subgroups are defined based on different cutoffs
> # (25th quantile of bene score, 50th, and 75th)
> plot(valmod, type = "conditional")
> 
> # visualize the frequency of particular variables
> # of being selected across the resampling iterations with
> # 'type = "stability"'
> # not run:
> # plot(valmod, type = "stability")
> 
> 
> 
> 
> cleanEx()
> nameEx("plotCompare")
> ### * plotCompare
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: plotCompare
> ### Title: Plot a comparison results for fitted or validated subgroup
> ###   identification models
> ### Aliases: plotCompare
> 
> ### ** Examples
> 
> library(personalized)
> 
> set.seed(123)
> n.obs  <- 100
> n.vars <- 15
> x <- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)
> 
> 
> # simulate non-randomized treatment
> xbetat   <- 0.5 + 0.5 * x[,1] - 0.5 * x[,4]
> trt.prob <- exp(xbetat) / (1 + exp(xbetat))
> trt01    <- rbinom(n.obs, 1, prob = trt.prob)
> 
> trt      <- 2 * trt01 - 1
> 
> # simulate response
> delta <- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12])
> xbeta <- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13]
> xbeta <- xbeta + delta * trt
> 
> # continuous outcomes
> y <- drop(xbeta) + rnorm(n.obs, sd = 2)
> 
> # create function for fitting propensity score model
> prop.func <- function(x, trt)
+ {
+     # fit propensity score model
+     propens.model <- cv.glmnet(y = trt,
+                                x = x, family = "binomial")
+     pi.x <- predict(propens.model, s = "lambda.min",
+                     newx = x, type = "response")[,1]
+     pi.x
+ }
> 
> subgrp.model <- fit.subgroup(x = x, y = y,
+                            trt = trt01,
+                            propensity.func = prop.func,
+                            loss   = "sq_loss_lasso",
+                            nfolds = 5)              # option for cv.glmnet
> 
> 
> subgrp.model.o <- fit.subgroup(x = x, y = y,
+                            trt = trt01,
+                            propensity.func = prop.func,
+                            loss   = "owl_logistic_flip_loss_lasso",
+                            nfolds = 5)
> 
> plotCompare(subgrp.model, subgrp.model.o)
> 
> 
> 
> 
> cleanEx()
> nameEx("predict")
> ### * predict
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: predict.subgroup_fitted
> ### Title: Function to predict either benefit scores or treatment
> ###   recommendations
> ### Aliases: predict.subgroup_fitted predict.wksvm
> 
> ### ** Examples
> 
> library(personalized)
> 
> set.seed(123)
> n.obs  <- 1000
> n.vars <- 50
> x <- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)
> 
> 
> # simulate non-randomized treatment
> xbetat   <- 0.5 + 0.5 * x[,21] - 0.5 * x[,41]
> trt.prob <- exp(xbetat) / (1 + exp(xbetat))
> trt01    <- rbinom(n.obs, 1, prob = trt.prob)
> 
> trt      <- 2 * trt01 - 1
> 
> # simulate response
> delta <- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12])
> xbeta <- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13]
> xbeta <- xbeta + delta * trt
> 
> # continuous outcomes
> y <- drop(xbeta) + rnorm(n.obs, sd = 2)
> 
> # create function for fitting propensity score model
> prop.func <- function(x, trt)
+ {
+     # fit propensity score model
+     propens.model <- cv.glmnet(y = trt,
+                                x = x, family = "binomial")
+     pi.x <- predict(propens.model, s = "lambda.min",
+                     newx = x, type = "response")[,1]
+     pi.x
+ }
> 
> subgrp.model <- fit.subgroup(x = x, y = y,
+                             trt = trt01,
+                             propensity.func = prop.func,
+                             loss   = "sq_loss_lasso",
+                             nfolds = 5)              # option for cv.glmnet
> 
> subgrp.model$subgroup.trt.effects
$subgroup.effects
Est of E[Y|T=0,Recom=0]-E[Y|T=/=0,Recom=0] 
                                  13.82066 
Est of E[Y|T=1,Recom=1]-E[Y|T=/=1,Recom=1] 
                                  21.13543 

$avg.outcomes
           Recommended 0 Recommended 1
Received 0     -11.69612    -26.732935
Received 1     -25.51678     -5.597509

$sample.sizes
           Recommended 0 Recommended 1
Received 0           218           205
Received 1           323           254

$overall.subgroup.effect
[1] 17.50753

> benefit.scores <- predict(subgrp.model, newx = x, type = "benefit.score")
> 
> rec.trt.grp <- predict(subgrp.model, newx = x, type = "trt.group")
> 
> 
> 
> cleanEx()
> nameEx("summarize.subgroups")
> ### * summarize.subgroups
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: summarize.subgroups
> ### Title: Summarizing covariates within estimated subgroups
> ### Aliases: summarize.subgroups summarize.subgroups.default
> ###   summarize.subgroups.subgroup_fitted
> 
> ### ** Examples
> 
> library(personalized)
> 
> set.seed(123)
> n.obs  <- 1000
> n.vars <- 50
> x <- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)
> 
> 
> # simulate non-randomized treatment
> xbetat   <- 0.5 + 0.5 * x[,21] - 0.5 * x[,41]
> trt.prob <- exp(xbetat) / (1 + exp(xbetat))
> trt01    <- rbinom(n.obs, 1, prob = trt.prob)
> 
> trt      <- 2 * trt01 - 1
> 
> # simulate response
> delta <- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12])
> xbeta <- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13]
> xbeta <- xbeta + delta * trt
> 
> # continuous outcomes
> y <- drop(xbeta) + rnorm(n.obs, sd = 2)
> 
> # create function for fitting propensity score model
> prop.func <- function(x, trt)
+ {
+     # fit propensity score model
+     propens.model <- cv.glmnet(y = trt,
+                                x = x, family = "binomial")
+     pi.x <- predict(propens.model, s = "lambda.min",
+                     newx = x, type = "response")[,1]
+     pi.x
+ }
> 
> subgrp.model <- fit.subgroup(x = x, y = y,
+                              trt = trt01,
+                              propensity.func = prop.func,
+                              loss   = "sq_loss_lasso",
+                              nfolds = 5)    # option for cv.glmnet
> 
> comp <- summarize.subgroups(subgrp.model)
> print(comp, p.value = 0.01)
    Avg (recom 0) Avg (recom 1)   0 - 1 SE (recom 0) SE (recom 1)
V2        -1.3890        1.9147 -3.3037       0.1124       0.1146
V3         1.4399       -1.8286  3.2686       0.1067       0.1118
V13       -0.5653        0.2542 -0.8195       0.1282       0.1405
> 
> # or we can simply supply the matrix x and the subgroups
> comp2 <- summarize.subgroups(x, subgroup = 1 * (subgrp.model$benefit.scores > 0))
> 
> print(comp2, p.value = 0.01)
    Avg (recom 0) Avg (recom 1)   0 - 1 SE (recom 0) SE (recom 1)
V2        -1.3890        1.9147 -3.3037       0.1124       0.1146
V3         1.4399       -1.8286  3.2686       0.1067       0.1118
V13       -0.5653        0.2542 -0.8195       0.1282       0.1405
> 
> 
> 
> 
> cleanEx()
> nameEx("treatment.effects")
> ### * treatment.effects
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: treatment.effects
> ### Title: Calculation of covariate-conditional treatment effects
> ### Aliases: treatment.effects treatment.effects.default treat.effects
> ###   treatment.effects.subgroup_fitted
> 
> ### ** Examples
> 
> library(personalized)
> 
> set.seed(123)
> n.obs  <- 1000
> n.vars <- 50
> x <- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)
> 
> 
> # simulate non-randomized treatment
> xbetat   <- 0.5 + 0.5 * x[,21] - 0.5 * x[,41]
> trt.prob <- exp(xbetat) / (1 + exp(xbetat))
> trt01    <- rbinom(n.obs, 1, prob = trt.prob)
> 
> trt      <- 2 * trt01 - 1
> 
> # simulate response
> delta <- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12])
> xbeta <- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13]
> xbeta <- xbeta + delta * trt
> 
> # continuous outcomes
> y <- drop(xbeta) + rnorm(n.obs, sd = 2)
> 
> # time-to-event outcomes
> surv.time <- exp(-20 - xbeta + rnorm(n.obs, sd = 1))
> cens.time <- exp(rnorm(n.obs, sd = 3))
> y.time.to.event  <- pmin(surv.time, cens.time)
> status           <- 1 * (surv.time <= cens.time)
> 
> # create function for fitting propensity score model
> prop.func <- function(x, trt)
+ {
+     # fit propensity score model
+     propens.model <- cv.glmnet(y = trt,
+                                x = x, family = "binomial")
+     pi.x <- predict(propens.model, s = "lambda.min",
+                     newx = x, type = "response")[,1]
+     pi.x
+ }
> 
> subgrp.model <- fit.subgroup(x = x, y = y,
+                              trt = trt01,
+                              propensity.func = prop.func,
+                              loss   = "sq_loss_lasso",
+                              nfolds = 5)    # option for cv.glmnet
> 
> trt_eff <- treatment.effects(subgrp.model)
> str(trt_eff)
List of 2
 $ delta: num [1:1000] -11.55 -9.8 4.52 -7.03 -26.16 ...
  ..- attr(*, "comparison.trts")= int 1
  ..- attr(*, "reference.trt")= int 0
  ..- attr(*, "trts")= int [1:2] 0 1
 $ gamma: logi NA
 - attr(*, "class")= chr [1:2] "individual_treatment_effects" "list"
> 
> trt_eff
Summary of individual treatment effects: 
E[Y|T=1, X] - E[Y|T=0, X]

   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
-57.436 -13.833  -2.261  -1.396  10.513  49.163 
> 
> 
> library(survival)
> subgrp.model.cox <- fit.subgroup(x = x, y = Surv(y.time.to.event, status),
+                            trt = trt01,
+                            propensity.func = prop.func,
+                            loss   = "cox_loss_lasso",
+                            nfolds = 5)              # option for cv.glmnet
> 
> trt_eff_c <- treatment.effects(subgrp.model.cox)
> str(trt_eff_c)
List of 2
 $ delta: logi NA
 $ gamma: num [1:1000] 0.623 0.776 1.114 0.867 0.393 ...
  ..- attr(*, "comparison.trts")= int 1
  ..- attr(*, "reference.trt")= int 0
  ..- attr(*, "trts")= int [1:2] 0 1
 - attr(*, "class")= chr [1:2] "individual_treatment_effects" "list"
> 
> trt_eff_c
Summary of individual treatment effects: 
E[Y|T=1, X] / E[Y|T=0, X]

Note: for survival outcomes, the above ratio is 
E[g(Y)|T=1, X] / E[g(Y)|T=0, X], 
where g() is a monotone increasing function of Y, 
the survival time

   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
 0.1875  0.7641  1.1018  1.2453  1.5316  4.2888 
> 
> 
> 
> 
> cleanEx()

detaching ‘package:survival’

> nameEx("validate.subgroup")
> ### * validate.subgroup
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: validate.subgroup
> ### Title: Validating fitted subgroup identification models
> ### Aliases: validate.subgroup
> 
> ### ** Examples
> 
> library(personalized)
> 
> set.seed(123)
> n.obs  <- 500
> n.vars <- 20
> x <- matrix(rnorm(n.obs * n.vars, sd = 3), n.obs, n.vars)
> 
> 
> # simulate non-randomized treatment
> xbetat   <- 0.5 + 0.5 * x[,11] - 0.5 * x[,13]
> trt.prob <- exp(xbetat) / (1 + exp(xbetat))
> trt01    <- rbinom(n.obs, 1, prob = trt.prob)
> 
> trt      <- 2 * trt01 - 1
> 
> # simulate response
> delta <- 2 * (0.5 + x[,2] - x[,3] - x[,11] + x[,1] * x[,12])
> xbeta <- x[,1] + x[,11] - 2 * x[,12]^2 + x[,13]
> xbeta <- xbeta + delta * trt
> 
> # continuous outcomes
> y <- drop(xbeta) + rnorm(n.obs, sd = 2)
> 
> # create function for fitting propensity score model
> prop.func <- function(x, trt)
+ {
+     # fit propensity score model
+     propens.model <- cv.glmnet(y = trt,
+                                x = x, family = "binomial")
+     pi.x <- predict(propens.model, s = "lambda.min",
+                     newx = x, type = "response")[,1]
+     pi.x
+ }
> 
> subgrp.model <- fit.subgroup(x = x, y = y,
+                              trt = trt01,
+                              propensity.func = prop.func,
+                              loss   = "sq_loss_lasso",
+                              nfolds = 5)    # option for cv.glmnet
> 
> 
> x.test <- matrix(rnorm(10 * n.obs * n.vars, sd = 3), 10 * n.obs, n.vars)
> 
> 
> # simulate non-randomized treatment
> xbetat.test   <- 0.5 + 0.5 * x.test[,11] - 0.5 * x.test[,13]
> trt.prob.test <- exp(xbetat.test) / (1 + exp(xbetat.test))
> trt01.test    <- rbinom(10 * n.obs, 1, prob = trt.prob.test)
> 
> trt.test      <- 2 * trt01.test - 1
> 
> # simulate response
> delta.test <- 2 * (0.5 + x.test[,2] - x.test[,3] - x.test[,11] + x.test[,1] * x.test[,12])
> xbeta.test <- x.test[,1] + x.test[,11] - 2 * x.test[,12]^2 + x.test[,13]
> xbeta.test <- xbeta.test + delta.test * trt.test
> 
> y.test <- drop(xbeta.test) + rnorm(10 * n.obs, sd = 2)
> 
> valmod <- validate.subgroup(subgrp.model, B = 3,
+                             method = "training_test",
+                             train.fraction = 0.75)
> valmod
family:  gaussian 
loss:    sq_loss_lasso 
method:  weighting 

validation method:  training_test_replication 
cutpoint:           0 
replications:       3 

benefit score: f(x), 
Trt recom = 1*I(f(x)>c)+0*I(f(x)<=c) where c is 'cutpoint'

Average Test Set Outcomes:
                                 Recommended 0
Received 0 -14.925 (SE = 13.5505, n = 12.6667)
Received 1        -18.6798 (SE = 2.02, n = 40)
                                 Recommended 1
Received 0     -19.1219 (SE = 10.6593, n = 41)
Received 1 -11.4523 (SE = 3.3954, n = 31.3333)

Treatment effects conditional on subgroups:
Est of E[Y|T=0,Recom=0]-E[Y|T=/=0,Recom=0] 
        3.7548 (SE = 15.5211, n = 52.6667) 
Est of E[Y|T=1,Recom=1]-E[Y|T=/=1,Recom=1] 
         7.6696 (SE = 8.0796, n = 72.3333) 

Est of 
E[Y|Trt received = Trt recom] - E[Y|Trt received =/= Trt recom]:                     
5.9962 (SE = 1.3495) 
> 
> print(valmod, which.quant = c(4, 5))
family:  gaussian 
loss:    sq_loss_lasso 
method:  weighting 

validation method:  training_test_replication 
cutpoint:           Quant_67 
replications:       3 

benefit score: f(x), 
Trt recom = 1*I(f(x)>c)+0*I(f(x)<=c) where c is 'cutpoint'

Average Test Set Outcomes:
                             Recommended 0                       Recommended 1
Received 0 -12.0424 (SE = 13.3332, n = 26) -31.4333 (SE = 7.6003, n = 27.6667)
Received 1  -16.8643 (SE = 0.9889, n = 58)  -8.8913 (SE = 4.8159, n = 13.3333)

Treatment effects conditional on subgroups:
Est of E[Y|T=0,Recom=0]-E[Y|T=/=0,Recom=0] 
             4.8219 (SE = 12.7916, n = 84) 
Est of E[Y|T=1,Recom=1]-E[Y|T=/=1,Recom=1] 
            22.5419 (SE = 11.7745, n = 41) 

Est of E[Y|Trt received = Trt recom] - E[Y|Trt received =/= Trt recom]:                      
10.5675 (SE = 9.0892) 

<===============================================>

family:  gaussian 
loss:    sq_loss_lasso 
method:  weighting 

validation method:  training_test_replication 
cutpoint:           Quant_83 
replications:       3 

benefit score: f(x), 
Trt recom = 1*I(f(x)>c)+0*I(f(x)<=c) where c is 'cutpoint'

Average Test Set Outcomes:
                             Recommended 0                       Recommended 1
Received 0 -14.0302 (SE = 10.6136, n = 37) -32.4616 (SE = 6.5468, n = 16.6667)
Received 1  -16.3633 (SE = 0.9549, n = 66)  -9.1074 (SE = 15.3114, n = 5.3333)

Treatment effects conditional on subgroups:
Est of E[Y|T=0,Recom=0]-E[Y|T=/=0,Recom=0] 
            2.3331 (SE = 10.4042, n = 103) 
Est of E[Y|T=1,Recom=1]-E[Y|T=/=1,Recom=1] 
             23.3541 (SE = 11.457, n = 22) 

Est of E[Y|Trt received = Trt recom] - E[Y|Trt received =/= Trt recom]:                     
6.3183 (SE = 8.4968) 
> 
> 
> 
> 
> cleanEx()
> nameEx("weighted.ksvm")
> ### * weighted.ksvm
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: weighted.ksvm
> ### Title: Fit weighted kernel svm model.
> ### Aliases: weighted.ksvm
> 
> ### ** Examples
> 
> 
> library(kernlab)

Attaching package: ‘kernlab’

The following object is masked from ‘package:ggplot2’:

    alpha

> 
> x <- matrix(rnorm(200 * 2), ncol = 2)
> 
> y <- 2 * (sin(x[,2]) ^ 2 * exp(-x[,2]) - 0.2 > rnorm(200, sd = 0.1)) - 1
> 
> weights <- runif(100, max = 1.5, min = 0.5)
> 
> wk <- weighted.ksvm(x = x[1:100,], y = y[1:100], C = c(0.1, 0.5, 1, 2, 10),
+                     weights = weights[1:100])
> 
> pr <- predict(wk, newx = x[101:200,])
> 
> mean(pr == y[101:200])
[1] 0.67
> 
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()

detaching ‘package:kernlab’

> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  19.731 0.786 20.643 0.001 0.004 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')

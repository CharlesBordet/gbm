
R version 4.0.0 (2020-04-24) -- "Arbor Day"
Copyright (C) 2020 The R Foundation for Statistical Computing
Platform: x86_64-apple-darwin17.0 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> pkgname <- "EZtune"
> source(file.path(R.home("share"), "R", "examples-header.R"))
> options(warn = 1)
> library('EZtune')
> 
> base::assign(".oldSearch", base::search(), pos = 'CheckExEnv')
> base::assign(".old_wd", base::getwd(), pos = 'CheckExEnv')
> cleanEx()
> nameEx("eztune")
> ### * eztune
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: eztune
> ### Title: Supervised Learning Function
> ### Aliases: eztune
> 
> ### ** Examples
> 
> library(mlbench)
> data(Sonar)
> sonar <- Sonar[sample(1:nrow(Sonar), 100), ]
> 
> y <- sonar[, 61]
> x <- sonar[, 1:10]
> 
> # Optimize an SVM using the default fast setting and Hooke-Jeeves
> eztune(x, y)
$n
[1] 50

$cost
[1] 35

$gamma
[1] 0.03125

$accuracy
[1] 0.8

$model

Call:
svm(formula = as.factor(y) ~ ., data = dat, cost = results$cost, 
    gamma = results$gamma)


Parameters:
   SVM-Type:  C-classification 
 SVM-Kernel:  radial 
       cost:  35 

Number of Support Vectors:  61


> 
> # Optimize an SVM with 3-fold cross validation and Hooke-Jeeves
> eztune(x, y, fast = FALSE, cross = 3)
$nfold
[1] 3

$cost
[1] 31.98999

$gamma
[1] 0.03125

$accuracy
[1] 0.76

$model

Call:
svm(formula = as.factor(y) ~ ., data = dat, cost = results$cost, 
    gamma = results$gamma)


Parameters:
   SVM-Type:  C-classification 
 SVM-Kernel:  radial 
       cost:  31.98999 

Number of Support Vectors:  62


> 
> # Optimize GBM using training set of 50 observations and Hooke-Jeeves
> eztune(x, y, method = "gbm", fast = 50)
$n
[1] 50

$n.trees
[1] 500

$interaction.depth
[1] 5

$n.minobsinnode
[1] 8

$shrinkage
[1] 0.09

$accuracy
[1] 0.76

$model
gbm::gbm(formula = y ~ ., distribution = "bernoulli", data = dat, 
    n.trees = results$n.trees, interaction.depth = results$interaction.depth, 
    n.minobsinnode = results$n.minobsinnode, shrinkage = results$shrinkage)
A gradient boosted model with bernoulli loss function.
500 iterations were performed.
There were 10 predictors of which 10 had non-zero influence.

> 
> # Optimize SVM with 25% of the observations as a training dataset
> # using a genetic algorithm
> eztune(x, y, method = "svm", optimizer = "ga", fast = 0.25)
$n
[1] 25

$cost
[1] 416.0024

$gamma
[1] 0.09478163

$accuracy
[1] 0.7466667

$model

Call:
svm(formula = as.factor(y) ~ ., data = dat, cost = results$cost, 
    gamma = results$gamma)


Parameters:
   SVM-Type:  C-classification 
 SVM-Kernel:  radial 
       cost:  416.0024 

Number of Support Vectors:  63


> 
> 
> 
> 
> cleanEx()

detaching ‘package:mlbench’

> nameEx("eztune_cv")
> ### * eztune_cv
> 
> flush(stderr()); flush(stdout())
> 
> ### Name: eztune_cv
> ### Title: Cross Validated Accuracy for Supervised Learning Model
> ### Aliases: eztune_cv
> 
> ### ** Examples
> 
> library(mlbench)
> data(Sonar)
> sonar <- Sonar[sample(1:nrow(Sonar), 100), ]
> 
> y <- sonar[, 61]
> x <- sonar[, 1:10]
> 
> sonar_default <- eztune(x, y)
> eztune_cv(x, y, sonar_default)
[1] 0.68
> 
> sonar_svm <- eztune(x, y, fast = FALSE, cross = 3)
> eztune_cv(x, y, sonar_svm)
[1] 0.7
> 
> sonar_gbm <- eztune(x, y, method = "gbm", fast = 50)
> eztune_cv(x, y, sonar_gbm)
[1] 0.71
> 
> 
> 
> 
> 
> ### * <FOOTER>
> ###
> cleanEx()

detaching ‘package:mlbench’

> options(digits = 7L)
> base::cat("Time elapsed: ", proc.time() - base::get("ptime", pos = 'CheckExEnv'),"\n")
Time elapsed:  7.023 0.392 8.853 1.594 0.393 
> grDevices::dev.off()
null device 
          1 
> ###
> ### Local variables: ***
> ### mode: outline-minor ***
> ### outline-regexp: "\\(> \\)?### [*]+" ***
> ### End: ***
> quit('no')
